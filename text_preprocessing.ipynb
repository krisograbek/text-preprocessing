{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# nltk.download()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, poland is a very beautiful country!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_with_upper = \"Hello, POLAND is a Very BeautiFul CountrY!\"\n",
    "text_with_upper.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Most of them use `string.punctuation`**\n",
    "\n",
    "\n",
    "\n",
    "Based on the [StackOverflow question](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "\n",
    "I ordered the solutions from the fastest to the slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts_text = \"HI!!! I overuse ... !(@*punctuations +-*/ and*(& other signs __*(&!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using `str.translate()` \n",
    "Probably the fastest way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puncts_text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    "`re` stands for Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 with string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "regex.sub('', puncts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 in a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(f'[{re.escape(string.punctuation)}]','', puncts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "\n",
    "Removes **not words** and **not spaces**\n",
    "\n",
    "Note: `re` treats underscore as a word so its results are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs __'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[^\\w\\s]','', puncts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a slower solution\n",
    "exclude = set(string.punctuation)\n",
    "\"\".join(ch for ch in puncts_text if ch not in exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `str.replace()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = puncts_text\n",
    "for c in string.punctuation:\n",
    "    clean_text = clean_text.replace(c, \"\")\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers Removal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_numbers = '12abcd405'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `str.translate` with `string.digits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_numbers.translate(str.maketrans('', '', string.digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\d+', '', text_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[0-9]+', '', text_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `join()` and NOT `isdigit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(i for i in text_numbers if not i.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `join()` and `isalpha()`\n",
    "\n",
    "This actually isn't the correct solution, because `isalpha()` is True only for letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(i for i in text_numbers if i.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Tags Removal\n",
    "\n",
    "Solutions from [Stack Overflow](https://stackoverflow.com/questions/753052/strip-html-from-strings-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"\"\"<tr class=\"color-5 negri a-bottom\">\n",
    "<td class=\"a-center\" width=\"11%\"><div style=\"min-width: 80px\">3-Pointers</div></td>\n",
    "<td><div class=\"left\" style=\"min-width: 120px; max-width:175px; width: 57%\">\n",
    "<div class=\"left margen-l2\">Player</div>\n",
    "<div class=\"right\"> Team</div>\n",
    "</div>\n",
    "</td>\n",
    "<td><div style=\"min-width: 60px; \">Season</div></td>\n",
    "<td><div class=\"\">W/L Game</div>\n",
    "</td>\n",
    "</tr>\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    " - begin with tag opening '<'\n",
    " - then not '<'\n",
    " - not '<' at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3-Pointers\\n\\nPlayer\\n Team\\n\\n\\nSeason\\nW/L Game\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<[^<]+?>', '', html_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `BeautifulSoup`\n",
    "\n",
    " - `get_text()` removes HTML tags\n",
    " - `strip = True` removes whitespaces and newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3-Pointers,Player,Team,Season,W/L Game'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "soup.get_text(\",\", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_comment = \"<img<!-- --> src=x onerror=alert(1);//><!-- -->\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both solutions fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img src=x onerror=alert(1);//>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<[^<]+?>', '', html_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src=x onerror=alert(1);//>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_comment, 'html.parser')\n",
    "soup.get_text(\",\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' src=x onerror=alert(1);//>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
    "no_tags = tag_re.sub('', html_comment)\n",
    "no_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' src=x onerror=alert(1);//&gt;'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "html.escape(no_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL Removal\n",
    "\n",
    "From this [StackOverflow Question](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/11332580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url = \"\"\"text1\n",
    "text2\n",
    "http://url.com/bla1/blah1/\n",
    "text3\n",
    "text4\n",
    "http://url.com/bla2/blah2/\n",
    "text5\n",
    "text6\n",
    "http://url.com/bla3/blah3/\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text1\\ntext2\\n\\ntext3\\ntext4\\n\\ntext5\\ntext6\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'http\\S+', '', text_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newlines, spaces and tabs removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `str.split()` and `join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str=\"I want to Remove all white \\t\\n\\n\\r spaces, new lines \\n and tabs \\t\"\n",
    "\" \".join(my_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    " - **`\\s` stands for whitespace character, equivalent to `[ \\n\\r\\t\\f]`**\n",
    " - **`\\S` stands for not whitespace character, equivalent to `[^\\s]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\s+', ' ', my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^\\S]+', ' ', my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\t\\n\\r\\f ]+', ' ', my_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re.findall()`\n",
    "\n",
    "Taken from [StackOverflow](https://stackoverflow.com/questions/4697882/how-can-i-find-all-matches-to-a-regular-expression-in-python)\n",
    "\n",
    "NOTE: I believe this approach is slower than the one with `re.sub()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white new lines and tabs '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = re.findall('[\\w]+ ', my_str)\n",
    "\"\".join(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis Removal\n",
    "\n",
    "Found [here](https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b#gistcomment-3315605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi 🤔 How is your 🙈 and 😌. Have a nice weekend 💕👭👙😀🌀'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emojis = u\"Hi 🤔 How is your 🙈 and 😌. Have a nice weekend 💕👭👙\\U0001F600\\U0001F300\"\n",
    "text_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi  How is your  and . Have a nice weekend '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_pattern = re.compile(pattern=\"[\"\n",
    "                    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U000024C2-\\U0001F251\"\n",
    "                    u\"\\U0001f926-\\U0001f937\"\n",
    "                    u\"\\U00010000-\\U0010ffff\"\n",
    "                    u\"\\u2640-\\u2642\"\n",
    "                    u\"\\u2600-\\u2B55\"\n",
    "                    u\"\\u200d\"\n",
    "                    u\"\\u23cf\"\n",
    "                    u\"\\u23e9\"\n",
    "                    u\"\\u231a\"\n",
    "                    u\"\\ufe0f\"  # dingbats\n",
    "                    u\"\\u3030\"\n",
    "                \"]+\", flags = re.UNICODE)\n",
    "\n",
    "emojis_pattern.sub(r'', text_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Malaga, aeeohello. Polish: nNcCsSeaozZzZ letters. German uoaoss letters'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "text_accented = \"Málaga, àéêöhello. Polish: ńŃćĆśŚęąóżŻźŹ letters. German üöäöß letters\"\n",
    "\n",
    "unidecode.unidecode(text_accented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling corrections\n",
    "\n",
    "Solutions from [StackOverflow](https://stackoverflow.com/questions/13928155/spell-checker-for-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spellchecker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I really need some corrections This sentence has misspelled words'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(text):\n",
    "    corrected_text = list()\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        next_word = word\n",
    "        if word in misspelled_words:\n",
    "            next_word = spell.correction(word)\n",
    "        corrected_text.append(next_word)\n",
    "    \n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "text_misspelled = \"I realli needt smoe corection. This sentnce has mispelled wirds\"\n",
    "correct_spelling(text_misspelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `autocorrect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really need some correction. This sentence has misspelled words\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "speller = Speller(lang='en')\n",
    "\n",
    "print(speller(text_misspelled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `textblob`\n",
    "\n",
    "Found [here](https://www.geeksforgeeks.org/python-textblob-correct-method/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I really need some correction. His sentence has dispelled words\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "TextBlob(text_misspelled).correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.  The bedding was hardly able to cover it and seemed ready to slide off any moment.  His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.  \"What\\'s happened to me?\" he thought.  It wasn\\'t a dream.  His room, a proper human room although a little too small, lay peacefully between its four familiar walls.  A collection of textile samples lay spread out on the table - Samsa was a travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame.  It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards the viewer.  Gregor then turned to look out the window at the dull weather.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('metamorphosis.txt', 'r') as f:\n",
    "    # without newlines\n",
    "    lines = [line.rstrip() for line in f]\n",
    "    # read text line by line including newlines \\n\n",
    "    # text_lines = f.readlines()\n",
    "\n",
    "N_LINES = 20\n",
    "text_lines = \" \".join([line for line in lines[:N_LINES]])\n",
    "text_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin.  He lay on\\nhis armour-like back, and if he lifted his head a little he could\\nsee his brown belly, slightly domed and divided by arches into stiff\\nsections.  The bedding was hardl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the whole file\n",
    "with open('metamorphosis.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "N_CHARS = 300\n",
    "text_chars = text[:N_CHARS]\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'He', 'lay', 'on', 'his', 'armour-like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', '.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '.', '``', 'What', \"'s\", 'happened', 'to', 'me', '?', \"''\", 'he', 'thought', '.', 'It', 'was', \"n't\", 'a', 'dream', '.', 'His', 'room', ',', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', ',', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls', '.', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', '-', 'Samsa', 'was', 'a', 'travelling', 'salesman', '-', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice', ',', 'gilded', 'frame', '.', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright', ',', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards', 'the', 'viewer', '.', 'Gregor', 'then', 'turned', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text_tokens = word_tokenize(text_lines)\n",
    "print(len(text_tokens), text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens from the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'He', 'lay', 'on', 'his', 'armour-like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', '.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '.', '``', 'What', \"'s\", 'happened', 'to', 'me', '?', \"''\", 'he', 'thought', '.', 'It', 'was', \"n't\", 'a', 'dream', '.', 'His', 'room', ',', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', ',', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls', '.', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', '-', 'Samsa', 'was', 'a', 'travelling', 'salesman', '-', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice', ',', 'gilded', 'frame', '.', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright', ',', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards', 'the', 'viewer', '.', 'Gregor', 'then', 'turned', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "print(len(text_tokens), text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "# print(len(stop_words),stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 ['One', 'morning', ',', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', ',', 'found', 'transformed', 'bed', 'horrible', 'vermin', '.', 'lay', 'armour-like', 'back', ',', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', ',', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', '.', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment', '.', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'size', 'rest', ',', 'waved', 'helplessly', 'looked', '.', '``', \"'s\", 'happened', '?', \"''\", 'thought', '.', \"n't\", 'dream', '.', 'room', ',', 'proper', 'human', 'room', 'although', 'little', 'small', ',', 'lay', 'peacefully', 'four', 'familiar', 'walls', '.', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', '-', 'Samsa', 'travelling', 'salesman', '-', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', ',', 'gilded', 'frame', '.', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', ',', 'raising', 'heavy', 'fur', 'muff', 'covered', 'whole', 'lower', 'arm', 'towards', 'viewer', '.', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [word for word in text_tokens if word.lower() not in stop_words]\n",
    "print(len(filtered_tokens), filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 ['one', 'morning', ',', 'Gregor', 'Samsa', 'wake', 'troubled', 'dream', ',', 'find', 'transform', 'bed', 'horrible', 'vermin', '.', 'lie', 'armour', '-', 'like', 'back', ',', 'lift', 'head', 'little', 'could', 'see', 'brown', 'belly', ',', 'slightly', 'dome', 'divided', 'arch', 'stiff', 'section', '.', 'bed', 'hardly', 'able', 'cover', 'seem', 'ready', 'slide', 'moment', '.', 'many', 'leg', ',', 'pitifully', 'thin', 'compare', 'size', 'rest', ',', 'wave', 'helplessly', 'look', '.', '`', '`', 'be', 'happen', '?', \"''\", 'think', '.', 'not', 'dream', '.', 'room', ',', 'proper', 'human', 'room', 'although', 'little', 'small', ',', 'lie', 'peacefully', 'four', 'familiar', 'wall', '.', 'collection', 'textile', 'sample', 'lay', 'spread', 'table', '-', 'samsa', 'travel', 'salesman', '-', 'hang', 'picture', 'recently', 'cut', 'illustrate', 'magazine', 'house', 'nice', ',', 'gild', 'frame', '.', 'show', 'lady', 'fit', 'fur', 'hat', 'fur', 'boa', 'sit', 'upright', ',', 'raise', 'heavy', 'fur', 'muff', 'cover', 'whole', 'low', 'arm', 'towards', 'viewer', '.', 'Gregor', 'turn', 'look', 'window', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_text = \" \".join([token for token in filtered_tokens])\n",
    "lemmas = [word.lemma_ for word in nlp(filtered_text)]\n",
    "print(len(lemmas), lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a4f0234084b86db25ca1539382b5a4944f4886887c3cc83d09ff270c40bf732"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
