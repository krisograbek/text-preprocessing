{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# nltk.download()\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, poland is a very beautiful country!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_with_upper = \"Hello, POLAND is a Very BeautiFul CountrY!\"\n",
    "text_with_upper.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Most of them use `string.punctuation`**\n",
    "\n",
    "\n",
    "\n",
    "Based on the [StackOverflow question](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "\n",
    "I ordered the solutions from the fastest to the slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts_text = \"HI!!! I overuse ... !(@*punctuations +-*/ and*(& other signs __*(&!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using `str.translate()` \n",
    "Probably the fastest way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puncts_text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    "`re` stands for Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 with string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "regex.sub('', puncts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 in a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(f'[{re.escape(string.punctuation)}]','', puncts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "\n",
    "Removes **not words** and **not spaces**\n",
    "\n",
    "Note: `re` treats underscore as a word so its results are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs __'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[^\\w\\s]','', puncts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a slower solution\n",
    "exclude = set(string.punctuation)\n",
    "\"\".join(ch for ch in puncts_text if ch not in exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `str.replace()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI I overuse  punctuations  and other signs '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = puncts_text\n",
    "for c in string.punctuation:\n",
    "    clean_text = clean_text.replace(c, \"\")\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers Removal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_numbers = '12abcd405'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `str.translate` with `string.digits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_numbers.translate(str.maketrans('', '', string.digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\d+', '', text_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[0-9]+', '', text_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `join()` and NOT `isdigit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(i for i in text_numbers if not i.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `join()` and `isalpha()`\n",
    "\n",
    "This actually isn't the correct solution, because `isalpha()` is True only for letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(i for i in text_numbers if i.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Tags Removal\n",
    "\n",
    "Solutions from [Stack Overflow](https://stackoverflow.com/questions/753052/strip-html-from-strings-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"\"\"<tr class=\"color-5 negri a-bottom\">\n",
    "<td class=\"a-center\" width=\"11%\"><div style=\"min-width: 80px\">3-Pointers</div></td>\n",
    "<td><div class=\"left\" style=\"min-width: 120px; max-width:175px; width: 57%\">\n",
    "<div class=\"left margen-l2\">Player</div>\n",
    "<div class=\"right\"> Team</div>\n",
    "</div>\n",
    "</td>\n",
    "<td><div style=\"min-width: 60px; \">Season</div></td>\n",
    "<td><div class=\"\">W/L Game</div>\n",
    "</td>\n",
    "</tr>\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    " - begin with tag opening '<'\n",
    " - then not '<'\n",
    " - not '<' at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3-Pointers\\n\\nPlayer\\n Team\\n\\n\\nSeason\\nW/L Game\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<[^<]+?>', '', html_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `BeautifulSoup`\n",
    "\n",
    " - `get_text()` removes HTML tags\n",
    " - `strip = True` removes whitespaces and newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3-Pointers,Player,Team,Season,W/L Game'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "soup.get_text(\",\", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_comment = \"<img<!-- --> src=x onerror=alert(1);//><!-- -->\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both solutions fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img src=x onerror=alert(1);//>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<[^<]+?>', '', html_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src=x onerror=alert(1);//>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_comment, 'html.parser')\n",
    "soup.get_text(\",\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' src=x onerror=alert(1);//>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
    "no_tags = tag_re.sub('', html_comment)\n",
    "no_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' src=x onerror=alert(1);//&gt;'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "html.escape(no_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL Removal\n",
    "\n",
    "From this [StackOverflow Question](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/11332580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url = \"\"\"text1\n",
    "text2\n",
    "http://url.com/bla1/blah1/\n",
    "text3\n",
    "text4\n",
    "http://url.com/bla2/blah2/\n",
    "text5\n",
    "text6\n",
    "http://url.com/bla3/blah3/\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text1\\ntext2\\n\\ntext3\\ntext4\\n\\ntext5\\ntext6\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'http\\S+', '', text_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newlines, spaces and tabs removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `str.split()` and `join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str=\"I want to Remove all white \\t\\n\\n\\r spaces, new lines \\n and tabs \\t\"\n",
    "\" \".join(my_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    " - **`\\s` stands for whitespace character, equivalent to `[ \\n\\r\\t\\f]`**\n",
    " - **`\\S` stands for not whitespace character, equivalent to `[^\\s]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\s+', ' ', my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^\\S]+', ' ', my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white spaces, new lines and tabs '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\t\\n\\r\\f ]+', ' ', my_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re.findall()`\n",
    "\n",
    "Taken from [StackOverflow](https://stackoverflow.com/questions/4697882/how-can-i-find-all-matches-to-a-regular-expression-in-python)\n",
    "\n",
    "NOTE: I believe this approach is slower than the one with `re.sub()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to Remove all white new lines and tabs '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = re.findall('[\\w]+ ', my_str)\n",
    "\"\".join(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis Removal\n",
    "\n",
    "Found [here](https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b#gistcomment-3315605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi ðŸ¤” How is your ðŸ™ˆ and ðŸ˜Œ. Have a nice weekend ðŸ’•ðŸ‘­ðŸ‘™ðŸ˜€ðŸŒ€'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emojis = u\"Hi ðŸ¤” How is your ðŸ™ˆ and ðŸ˜Œ. Have a nice weekend ðŸ’•ðŸ‘­ðŸ‘™\\U0001F600\\U0001F300\"\n",
    "text_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi  How is your  and . Have a nice weekend '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_pattern = re.compile(pattern=\"[\"\n",
    "                    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U000024C2-\\U0001F251\"\n",
    "                    u\"\\U0001f926-\\U0001f937\"\n",
    "                    u\"\\U00010000-\\U0010ffff\"\n",
    "                    u\"\\u2640-\\u2642\"\n",
    "                    u\"\\u2600-\\u2B55\"\n",
    "                    u\"\\u200d\"\n",
    "                    u\"\\u23cf\"\n",
    "                    u\"\\u23e9\"\n",
    "                    u\"\\u231a\"\n",
    "                    u\"\\ufe0f\"  # dingbats\n",
    "                    u\"\\u3030\"\n",
    "                \"]+\", flags = re.UNICODE)\n",
    "\n",
    "emojis_pattern.sub(r'', text_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Malaga, aeeohello. Polish: nNcCsSeaozZzZ letters. German uoaoss letters'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "text_accented = \"MÃ¡laga, Ã Ã©ÃªÃ¶hello. Polish: Å„ÅƒÄ‡Ä†Å›ÅšÄ™Ä…Ã³Å¼Å»ÅºÅ¹ letters. German Ã¼Ã¶Ã¤Ã¶ÃŸ letters\"\n",
    "\n",
    "unidecode.unidecode(text_accented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling corrections\n",
    "\n",
    "Solutions from [StackOverflow](https://stackoverflow.com/questions/13928155/spell-checker-for-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spellchecker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I really need some corrections This sentence has misspelled words'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(text):\n",
    "    corrected_text = list()\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        next_word = word\n",
    "        if word in misspelled_words:\n",
    "            next_word = spell.correction(word)\n",
    "        corrected_text.append(next_word)\n",
    "    \n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "text_misspelled = \"I realli needt smoe corection. This sentnce has mispelled wirds\"\n",
    "correct_spelling(text_misspelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `autocorrect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really need some correction. This sentence has misspelled words\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "speller = Speller(lang='en')\n",
    "\n",
    "print(speller(text_misspelled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `textblob`\n",
    "\n",
    "Found [here](https://www.geeksforgeeks.org/python-textblob-correct-method/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I really need some correction. His sentence has dispelled words\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "TextBlob(text_misspelled).correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.  The bedding was hardly able to cover it and seemed ready to slide off any moment.  His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.  \"What\\'s happened to me?\" he thought.  It wasn\\'t a dream.  His room, a proper human room although a little too small, lay peacefully between its four familiar walls.  A collection of textile samples lay spread out on the table - Samsa was a travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame.  It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards the viewer.  Gregor then turned to look out the window at the dull weather.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('metamorphosis.txt', 'r') as f:\n",
    "    # without newlines\n",
    "    lines = [line.rstrip() for line in f]\n",
    "    # read text line by line including newlines \\n\n",
    "    # text_lines = f.readlines()\n",
    "\n",
    "N_LINES = 20\n",
    "text_lines = \" \".join([line for line in lines[:N_LINES]])\n",
    "text_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin.  He lay on\\nhis armour-like back, and if he lifted his head a little he could\\nsee his brown belly, slightly domed and divided by arches into stiff\\nsections.  The bedding was hardl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the whole file\n",
    "with open('metamorphosis.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "N_CHARS = 300\n",
    "text_chars = text[:N_CHARS]\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`\n",
    "\n",
    "Return the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armour', 'like', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 's', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasn', 't', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', 'Samsa', 'was', 'a', 'travelling', 'salesman', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice', 'gilded', 'frame', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards', 'the', 'viewer', 'Gregor', 'then', 'turned', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather']\n"
     ]
    }
   ],
   "source": [
    "re_tokens = re.findall('[\\w]+', text_lines)\n",
    "print(len(re_tokens))\n",
    "print(re_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'He', 'lay', 'on', 'his', 'armour-like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', '.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '.', '``', 'What', \"'s\", 'happened', 'to', 'me', '?', \"''\", 'he', 'thought', '.', 'It', 'was', \"n't\", 'a', 'dream', '.', 'His', 'room', ',', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', ',', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls', '.', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', '-', 'Samsa', 'was', 'a', 'travelling', 'salesman', '-', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice', ',', 'gilded', 'frame', '.', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright', ',', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards', 'the', 'viewer', '.', 'Gregor', 'then', 'turned', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk_tokens = word_tokenize(text_lines)\n",
    "print(len(nltk_tokens), nltk_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "[One, morning, ,, when, Gregor, Samsa, woke, from, troubled, dreams, ,, he, found, himself, transformed, in, his, bed, into, a, horrible, vermin, .,  , He, lay, on, his, armour, -, like, back, ,, and, if, he, lifted, his, head, a, little, he, could, see, his, brown, belly, ,, slightly, domed, and, divided, by, arches, into, stiff, sections, .,  , The, bedding, was, hardly, able, to, cover, it, and, seemed, ready, to, slide, off, any, moment, .,  , His, many, legs, ,, pitifully, thin, compared, with, the, size, of, the, rest, of, him, ,, waved, about, helplessly, as, he, looked, .,  , \", What, 's, happened, to, me, ?, \", he, thought, .,  , It, was, n't, a, dream, .,  , His, room, ,, a, proper, human, room, although, a, little, too, small, ,, lay, peacefully, between, its, four, familiar, walls, .,  , A, collection, of, textile, samples, lay, spread, out, on, the, table, -, Samsa, was, a, travelling, salesman, -, and, above, it, there, hung, a, picture, that, he, had, recently, cut, out, of, an, illustrated, magazine, and, housed, in, a, nice, ,, gilded, frame, .,  , It, showed, a, lady, fitted, out, with, a, fur, hat, and, fur, boa, who, sat, upright, ,, raising, a, heavy, fur, muff, that, covered, the, whole, of, her, lower, arm, towards, the, viewer, .,  , Gregor, then, turned, to, look, out, the, window, at, the, dull, weather, .]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text_lines)\n",
    "spacy_tokens = list([token for token in doc])\n",
    "print(len(spacy_tokens))\n",
    "print(spacy_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armour', 'like', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 's', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasn', 't', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', 'Samsa', 'was', 'a', 'travelling', 'salesman', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice', 'gilded', 'frame', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards', 'the', 'viewer', 'Gregor', 'then', 'turned', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather']\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "\n",
    "gensim_tokens = list(tokenize(text_lines))\n",
    "print(len(gensim_tokens))\n",
    "print(gensim_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Comparision\n",
    "\n",
    " - it seems that `gensim` uses the same `re` function, that we showed above. Both returned only words\n",
    " - `nltk` and `spacy` return also punctuations\n",
    " - `spacy` treats a whitespace as a token if there is a double whitespace. In our text each sentence-ending dot is followed by double whitespace. We could clean this but at least we see that `spacy` behaves differently\n",
    " - **not or n't** contraction gives different results. `spacy` and `nltk` splits *wasn't* to *was* and *n't*, whereas `re` and `gensim` to *wasn* and *t*.\n",
    " - when there is a hyphen between words, we get 3 different results. Our example is armour-like. `nltk` returns **a single token**: *armour-like*, `re` and `gensim` return **two tokens**: *armour* and *like*. `spacy` returns **three tokens**: *armour*, *-*, and *like*\n",
    " - `nltk` converts quotation marks. Quote opening: **``**, quote closing **' '**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " ['One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin',\n",
       "  '  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections',\n",
       "  '  The bedding was hardly able to cover it and seemed ready to slide off any moment',\n",
       "  '  His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked',\n",
       "  '  \"What\\'s happened to me',\n",
       "  '\" he thought',\n",
       "  \"  It wasn't a dream\",\n",
       "  '  His room, a proper human room although a little too small, lay peacefully between its four familiar walls',\n",
       "  '  A collection of textile samples lay spread out on the table - Samsa was a travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame',\n",
       "  '  It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards the viewer',\n",
       "  '  Gregor then turned to look out the window at the dull weather',\n",
       "  ''])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_sentences = re.compile('[.?!]').split(text_lines)\n",
    "len(re_sentences), re_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ['One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.', 'He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.', 'The bedding was hardly able to cover it and seemed ready to slide off any moment.', 'His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.', '\"What\\'s happened to me?\"', 'he thought.', \"It wasn't a dream.\", 'His room, a proper human room although a little too small, lay peacefully between its four familiar walls.', 'A collection of textile samples lay spread out on the table - Samsa was a travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame.', 'It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards the viewer.', 'Gregor then turned to look out the window at the dull weather.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk_sentences = sent_tokenize(text_lines)\n",
    "print(len(nltk_sentences), nltk_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,\n",
       " [One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.,\n",
       "   He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.,\n",
       "   The bedding was hardly able to cover it and seemed ready to slide off any moment.,\n",
       "   His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.,\n",
       "   \"What's happened to me?\",\n",
       "  he thought.,\n",
       "   It wasn't a dream.,\n",
       "   His room, a proper human room although a little too small, lay peacefully between its four familiar walls.,\n",
       "   A collection of textile samples lay spread out on the table - Samsa was a travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame.,\n",
       "   It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards the viewer.,\n",
       "   Gregor then turned to look out the window at the dull weather.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text_lines)\n",
    "spacy_sentences = list([sent for sent in doc.sents])\n",
    "len(spacy_sentences), spacy_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens from the original text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 ['One', 'morning', ',', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', ',', 'found', 'transformed', 'bed', 'horrible', 'vermin', '.', 'lay', 'armour-like', 'back', ',', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', ',', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', '.', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment', '.', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'size', 'rest', ',', 'waved', 'helplessly', 'looked', '.', '``', \"'s\", 'happened', '?', \"''\", 'thought', '.', \"n't\", 'dream', '.', 'room', ',', 'proper', 'human', 'room', 'although', 'little', 'small', ',', 'lay', 'peacefully', 'four', 'familiar', 'walls', '.', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', '-', 'Samsa', 'travelling', 'salesman', '-', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', ',', 'gilded', 'frame', '.', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', ',', 'raising', 'heavy', 'fur', 'muff', 'covered', 'whole', 'lower', 'arm', 'towards', 'viewer', '.', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_nltk = stopwords.words('english')\n",
    "# print(len(stop_words_nltk),stop_words_nltk)\n",
    "\n",
    "filtered_nltk = [word for word in nltk_tokens if word.lower() not in stop_words_nltk]\n",
    "print(len(filtered_nltk), filtered_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 [morning, ,, Gregor, Samsa, woke, troubled, dreams, ,, found, transformed, bed, horrible, vermin, .,  , lay, armour, -, like, ,, lifted, head, little, brown, belly, ,, slightly, domed, divided, arches, stiff, sections, .,  , bedding, hardly, able, cover, ready, slide, moment, .,  , legs, ,, pitifully, thin, compared, size, rest, ,, waved, helplessly, looked, .,  , \", happened, ?, \", thought, .,  , dream, .,  , room, ,, proper, human, room, little, small, ,, lay, peacefully, familiar, walls, .,  , collection, textile, samples, lay, spread, table, -, Samsa, travelling, salesman, -, hung, picture, recently, cut, illustrated, magazine, housed, nice, ,, gilded, frame, .,  , showed, lady, fitted, fur, hat, fur, boa, sat, upright, ,, raising, heavy, fur, muff, covered, lower, arm, viewer, .,  , Gregor, turned, look, window, dull, weather, .]\n"
     ]
    }
   ],
   "source": [
    "stop_words_spacy = nlp.Defaults.stop_words\n",
    "\n",
    "filtered_spacy = [word for word in spacy_tokens if word.text.lower() not in stop_words_spacy]\n",
    "print(len(filtered_spacy), filtered_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713 One morning, Gregor Samsa woke troubled dreams, transformed bed horrible vermin. He lay armour-like back, lifted head little brown belly, slightly domed divided arches stiff sections. The bedding hardly able cover ready slide moment. His legs, pitifully compared size rest him, waved helplessly looked. \"What's happened me?\" thought. It wasn't dream. His room, proper human room little small, lay peacefully familiar walls. A collection textile samples lay spread table - Samsa travelling salesman - hung picture recently cut illustrated magazine housed nice, gilded frame. It showed lady fitted fur hat fur boa sat upright, raising heavy fur muff covered lower arm viewer. Gregor turned look window dull weather.\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "filtered_sentence_gensim = remove_stopwords(text_lines)\n",
    "print(len(filtered_sentence_gensim), filtered_sentence_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 ['morning', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'lifted', 'head', 'little', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'ready', 'slide', 'moment', 'legs', 'pitifully', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 's', 'happened', 'thought', 'wasn', 't', 'dream', 'room', 'proper', 'human', 'room', 'little', 'small', 'lay', 'peacefully', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'Samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'lower', 'arm', 'viewer', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather']\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "stop_words_gensim = STOPWORDS\n",
    "\n",
    "filtered_tokens_gensim = [word for word in gensim_tokens if word.lower() not in stop_words_gensim]\n",
    "print(len(filtered_tokens_gensim), filtered_tokens_gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Stopwords Removal Only for Words (without Punctuation)\n",
    "\n",
    "Let's use tokens from `re` to comapare stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ['One', 'morning', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment', 'many', 'legs', 'pitifully', 'thin', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 'happened', 'thought', 'dream', 'room', 'proper', 'human', 'room', 'although', 'little', 'small', 'lay', 'peacefully', 'four', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'Samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'whole', 'lower', 'arm', 'towards', 'viewer', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather']\n"
     ]
    }
   ],
   "source": [
    "nltk_filt = [word for word in re_tokens if word.lower() not in stop_words_nltk]\n",
    "print(len(nltk_filt), nltk_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 ['morning', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'lifted', 'head', 'little', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'ready', 'slide', 'moment', 'legs', 'pitifully', 'thin', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 's', 'happened', 'thought', 'wasn', 't', 'dream', 'room', 'proper', 'human', 'room', 'little', 'small', 'lay', 'peacefully', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'Samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'lower', 'arm', 'viewer', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather']\n"
     ]
    }
   ],
   "source": [
    "spacy_filt = [word for word in re_tokens if word.lower() not in stop_words_spacy]\n",
    "print(len(spacy_filt), spacy_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 ['morning', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'lifted', 'head', 'little', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'ready', 'slide', 'moment', 'legs', 'pitifully', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 's', 'happened', 'thought', 'wasn', 't', 'dream', 'room', 'proper', 'human', 'room', 'little', 'small', 'lay', 'peacefully', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'Samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'lower', 'arm', 'viewer', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather']\n"
     ]
    }
   ],
   "source": [
    "gensim_filt = [word for word in re_tokens if word.lower() not in stop_words_gensim]\n",
    "print(len(gensim_filt), gensim_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`nltk` vs `spacy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seemed',\n",
       " 'One',\n",
       " 'wasn',\n",
       " 'towards',\n",
       " 'see',\n",
       " 's',\n",
       " 'four',\n",
       " 'back',\n",
       " 'although',\n",
       " 'many',\n",
       " 'could',\n",
       " 'whole',\n",
       " 't']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(nltk_filt) ^ set(spacy_filt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`nltk` vs `gensim`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seemed',\n",
       " 'One',\n",
       " 'found',\n",
       " 'wasn',\n",
       " 'thin',\n",
       " 'towards',\n",
       " 'see',\n",
       " 's',\n",
       " 'four',\n",
       " 'back',\n",
       " 'although',\n",
       " 'many',\n",
       " 'could',\n",
       " 'whole',\n",
       " 't']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(nltk_filt) ^ set(gensim_filt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`gensim` vs `spacy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['found', 'thin']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(gensim_filt) ^ set(spacy_filt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing stopwords lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"NLTK stopwords\",stop_words_nltk)\n",
    "# print(\"Spacy stopwords\",stop_words_spacy)\n",
    "# print(\"Gensim stopwords\",stop_words_gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK stopwords len 179\n",
      "Spacy stopwords len 326\n",
      "Gensim stopwords len 337\n"
     ]
    }
   ],
   "source": [
    "print(\"NLTK stopwords len\", len(stop_words_nltk))\n",
    "print(\"Spacy stopwords len\", len(stop_words_spacy))\n",
    "print(\"Gensim stopwords len\", len(stop_words_gensim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 ['one', 'morning', ',', 'when', 'Gregor', 'Samsa', 'wake', 'from', 'troubled', 'dream', ',', 'he', 'find', 'himself', 'transform', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', '  ', 'he', 'lie', 'on', 'his', 'armour', '-', 'like', 'back', ',', 'and', 'if', 'he', 'lift', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divide', 'by', 'arch', 'into', 'stiff', 'section', '.', '  ', 'the', 'bedding', 'be', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seem', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', '  ', 'his', 'many', 'leg', ',', 'pitifully', 'thin', 'compare', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'he', ',', 'wave', 'about', 'helplessly', 'as', 'he', 'look', '.', '  ', '\"', 'what', 'be', 'happen', 'to', 'I', '?', '\"', 'he', 'think', '.', '  ', 'it', 'be', 'not', 'a', 'dream', '.', '  ', 'his', 'room', ',', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', ',', 'lie', 'peacefully', 'between', 'its', 'four', 'familiar', 'wall', '.', '  ', 'a', 'collection', 'of', 'textile', 'sample', 'lie', 'spread', 'out', 'on', 'the', 'table', '-', 'Samsa', 'be', 'a', 'travel', 'salesman', '-', 'and', 'above', 'it', 'there', 'hang', 'a', 'picture', 'that', 'he', 'have', 'recently', 'cut', 'out', 'of', 'an', 'illustrate', 'magazine', 'and', 'house', 'in', 'a', 'nice', ',', 'gild', 'frame', '.', '  ', 'it', 'show', 'a', 'lady', 'fit', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sit', 'upright', ',', 'raise', 'a', 'heavy', 'fur', 'muff', 'that', 'cover', 'the', 'whole', 'of', 'her', 'low', 'arm', 'towards', 'the', 'viewer', '.', '  ', 'Gregor', 'then', 'turn', 'to', 'look', 'out', 'the', 'window', 'at', 'the', 'dull', 'weather', '.']\n"
     ]
    }
   ],
   "source": [
    "spacy_text = \" \".join([token.text for token in spacy_tokens])\n",
    "lemmas = [word.lemma_ for word in nlp(spacy_text)]\n",
    "print(len(lemmas), lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a4f0234084b86db25ca1539382b5a4944f4886887c3cc83d09ff270c40bf732"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
